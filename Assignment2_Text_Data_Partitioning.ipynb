{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cdb7dfd2",
      "metadata": {
        "id": "cdb7dfd2"
      },
      "source": [
        "## Text Data Partitioning\n",
        "\n",
        "### Guidance</br>\n",
        "<li>obtain the list of books by using .fileids() function. </li>\n",
        "<li>import data from Gutenberg by using .raw() function. </li>\n",
        "<li>tokenization of words by using word_tokenize() function. </li>\n",
        "<li>create 200 random sample of 100 words for each book. </li>\n",
        "<li>use for loop </li>\n",
        "<li>divide the tokenized words into chunks and label the chunks </li>\n",
        "<li>use random.randint() function to randomly pick a start position for selecting the 150 words </li>\n",
        "<li>use append function to label each chunk to the corresponding label (e.g., author name) </li>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9aee363e",
      "metadata": {
        "id": "9aee363e"
      },
      "source": [
        "## Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "212df1a6",
      "metadata": {
        "id": "212df1a6"
      },
      "outputs": [],
      "source": [
        "# import necessary libraries and modules\n",
        "import math\n",
        "import re\n",
        "import nltk\n",
        "import csv\n",
        "import random\n",
        "import pandas as pd\n",
        "from urllib import request\n",
        "from nltk.corpus import gutenberg, stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6303b370",
      "metadata": {
        "id": "6303b370"
      },
      "source": [
        "## Obtaining the list of books"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9351e52a",
      "metadata": {
        "id": "9351e52a"
      },
      "outputs": [],
      "source": [
        "# obtain the list of books by using .fileids() function.\n",
        "list_of_books=nltk.corpus.gutenberg.fileids()\n",
        "list_of_books"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fd31c5d",
      "metadata": {
        "id": "8fd31c5d"
      },
      "outputs": [],
      "source": [
        "# define 3 books for using\n",
        "books= ['austen-sense.txt','bible-kjv.txt','chesterton-brown.txt']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fbbe991",
      "metadata": {
        "id": "6fbbe991"
      },
      "source": [
        "## Creating function that\n",
        "<li>tokenizes words by using word_tokenize() function.</li>\n",
        "<li>creates 200 random sample of 100 words for each book.</li>\n",
        "<li>divides the tokenized words into chunks and label the chunks.</li>\n",
        "<li>randomly picks a start position for selecting the 150 words.</li>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23057ae6",
      "metadata": {
        "id": "23057ae6"
      },
      "outputs": [],
      "source": [
        "def read_book(Name):\n",
        "    # read the raw text of the book\n",
        "    book = nltk.corpus.gutenberg.raw(Name)\n",
        "    # tokenize the book text using word_tokenize() function\n",
        "    tokenize_book = word_tokenize(book)\n",
        "    # filter out tokens that are not alphanumeric and have a length less than 2\n",
        "    tokenize_book = [token for token in tokenize_book if token.isalnum() and len(token) >= 2]\n",
        "    # initialize an empty list for the partitions\n",
        "    list_of_part = []\n",
        "    # generate 200 partitions of 100-word sequences from the book\n",
        "    for i in range(200):\n",
        "        start = random.randint(0, len(tokenize_book)-100)\n",
        "        # append the 100-word sequence to the 'list_of_part' list as a string\n",
        "        list_of_part.append(' '.join(tokenize_book[start:start+100]))\n",
        "    # create a Pandas DataFrame with the partitions from 'list_of_part' and add a 'label' column with the book Name\n",
        "    df = pd.DataFrame({\"Chunks\": list_of_part, \"Label\": re.sub(r\".txt\", \"\", Name)})\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2aa05880",
      "metadata": {
        "id": "2aa05880"
      },
      "source": [
        "## Use for loop to loop 3 book"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e8c66fc",
      "metadata": {
        "id": "9e8c66fc",
        "outputId": "4267cf3e-d1d8-4f8c-ab0e-46e59cd1dbf6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_12780\\2478111275.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  data=data.append(df,ignore_index=True)\n",
            "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_12780\\2478111275.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  data=data.append(df,ignore_index=True)\n",
            "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_12780\\2478111275.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  data=data.append(df,ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "data=pd.DataFrame()\n",
        "df=pd.DataFrame()\n",
        "for name in books:\n",
        "    df=read_book(name)\n",
        "    data=data.append(df,ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc1c11a6",
      "metadata": {
        "id": "fc1c11a6",
        "outputId": "c88685d9-fc06-49fe-d75b-a17695597382"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['austen-sense', 'bible-kjv', 'chesterton-brown'], dtype=object)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# display the unique names of books\n",
        "data['Label'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72892613",
      "metadata": {
        "id": "72892613"
      },
      "outputs": [],
      "source": [
        "# define a dictionary to map the unique values of 3 books in label column to a, b, and c\n",
        "mapping = {'austen-sense': 'a', 'bible-kjv': 'b', 'chesterton-brown': 'c'}\n",
        "\n",
        "# replace the unique values with a, b, and c using the mapping dictionary\n",
        "data['Label'] = data['Label'].replace(mapping)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71193a97",
      "metadata": {
        "id": "71193a97",
        "outputId": "51a9dae7-1f72-4fa6-f504-e4c51e823d24"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Chunks</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>of It wo Then came your dear mother to torture...</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the time but was declared over again the next ...</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Elinor one which with Delaford living was all ...</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>am sure they are dearer Elinor heart which had...</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Elinor uneasiness was at least equal to her mo...</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>by all accounts almost at do think she continu...</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>his father was by this arrangement rendered Th...</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>mind be satisfied with wife like her illiterat...</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>my misery and my penitence tell her that my he...</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>women as Fanny would like to associate with Bu...</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Chunks Label\n",
              "0    of It wo Then came your dear mother to torture...     a\n",
              "1    the time but was declared over again the next ...     a\n",
              "2    Elinor one which with Delaford living was all ...     a\n",
              "3    am sure they are dearer Elinor heart which had...     a\n",
              "4    Elinor uneasiness was at least equal to her mo...     a\n",
              "..                                                 ...   ...\n",
              "195  by all accounts almost at do think she continu...     a\n",
              "196  his father was by this arrangement rendered Th...     a\n",
              "197  mind be satisfied with wife like her illiterat...     a\n",
              "198  my misery and my penitence tell her that my he...     a\n",
              "199  women as Fanny would like to associate with Bu...     a\n",
              "\n",
              "[200 rows x 2 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# print the first 200 rows of the 'data' DataFrame\n",
        "data.head(200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa16cbf7",
      "metadata": {
        "id": "fa16cbf7"
      },
      "outputs": [],
      "source": [
        "# convert dataframe to csv file\n",
        "data.to_csv('Result_file.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ea30361",
      "metadata": {
        "id": "3ea30361"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}